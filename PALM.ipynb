{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 方案说明\n",
    "本方案是一个简单的根据0基础入门的示例中的识别手写数字改写而成的 常规赛：PALM眼底彩照视盘探测与分割 程序。<br />\n",
    "本方案直接进行分割，不进行图片分类，因为按照理论来说，如果眼睛正常，并且神经网络学习到了所有的信息，则会将正常眼球照片分割为整块的白色，仅对病变部分分割出黑色。但实际上，这种认知是假设性的，因为神经网络只是有机会学到这个信息，有多大概率学到这个内容是完全不受保证的，所以对于实际问题，我建议务必考虑将分类和分割联系在一起做，而不是用分割程序简单代替分类。<br />\n",
    "本方案得分0.64594，DICE为0.42351，F1值为0.97959。\n",
    "\n",
    "本方案从头到尾直接运行即可，整体布局为 **数据获取 -> 构造模型和数据读取器 -> 训练 -> 预测 -> 平滑处理和打包**。<br />\n",
    "\n",
    "## 具体实现策略<br />\n",
    "&ensp;&ensp;1. 依次读取训练图片，将图片转为灰度模式，将图片缩放到指定尺寸。<br />\n",
    "&ensp;&ensp;2. 构造神经网络和数据读取器，这部分直接参考0基础入门的示例中的识别手写数字。<br />\n",
    "&ensp;&ensp;3. 训练数据，通过文件名分批次读取数据进行训练。<br />\n",
    "&ensp;&ensp;4. 预测数据，通过文件名分批次读取数据进行预测。<br />\n",
    "&ensp;&ensp;5. 预测后的结果通常来说并不能完美地划分，总是包含很多噪点（比如说对于大部分应当处于黑色部分的像素点是黑色，但是仍有一部分像素点是白色的），因此通过一个卷积层进行平滑操作。最后将平滑后的结果缩放到原图片大小，打包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 刷新内存资源\r\n",
    "! rm -rf ./work/\r\n",
    "! mkdir ./work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载数据与解压数据\r\n",
    "url='https://bj.bcebos.com/v1/dataset-bj/%E5%8C%BB%E7%96%97%E6%AF%94%E8%B5%9B/%E5%B8%B8%E8%A7%84%E8%B5%9B%EF%BC%9APALM%E7%9C%BC%E5%BA%95%E5%BD%A9%E7%85%A7%E8%A7%86%E7%9B%98%E6%8E%A2%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2.zip'\r\n",
    "\r\n",
    "if not os.path.exists('./work/Train_and_test.zip'):\r\n",
    "    print(\"Downloading start!\")\r\n",
    "    urllib.request.urlretrieve(url, \"./work/Train_and_test.zip\")  \r\n",
    "    print(\"Downloading end!\")\r\n",
    "else:\r\n",
    "    print(\"Already Downloading\")\r\n",
    "\r\n",
    "! unzip ./work/Train_and_test.zip -d ./work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 程序开始\n",
    "## 引入包\n",
    "\n",
    "自定义变量包括:<br />\n",
    "&ensp;&ensp;image_size \t\t # 缩放图片的大小<br />\n",
    "&ensp;&ensp;batchsize\t   \t# 每次读取数据的大小<br />\n",
    "&ensp;&ensp;epoch_num\t\t # 训练批次<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 引入包以及全局变量声明\r\n",
    "import paddle\r\n",
    "import paddle.nn.functional as F\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear\r\n",
    "import pandas as pd\r\n",
    "from PIL import Image\r\n",
    "import sys \r\n",
    "import random\r\n",
    "import urllib \r\n",
    "import requests   \r\n",
    "from paddle.nn.initializer import Assign\r\n",
    "\r\n",
    "global image_size;\r\n",
    "global batchsize;\r\n",
    "\r\n",
    "image_size=64;\r\n",
    "batchsize=100;\r\n",
    "epoch_num=3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 图片分割\n",
    "### 构造神经网络并定义数据读取器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义一个三层全连接层组成的网络\r\n",
    "class Mymodel(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(Mymodel, self).__init__()\r\n",
    "        global image_size\r\n",
    "        self.fc = Linear(in_features=image_size*image_size, out_features=image_size*image_size*4)\r\n",
    "        self.fc2 = Linear(in_features=image_size*image_size*4, out_features=image_size*image_size*4)\r\n",
    "        self.fc3 = Linear(in_features=image_size*image_size*4, out_features=image_size*image_size)\r\n",
    "\r\n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc(inputs);\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.fc3(x);\r\n",
    "        x = F.sigmoid(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "# 定义数据读取器\r\n",
    "def load_data(mylist,mode='train'):\r\n",
    "    global image_size\r\n",
    "    global batchsize\r\n",
    "    # 默认使用灰度图像\r\n",
    "    input_channel=1\r\n",
    "    \r\n",
    "    # 根据需要指定对应的文件目录\r\n",
    "    if mode == 'train':\r\n",
    "        path='work/常规赛：PALM眼底彩照视盘探测与分割/Train/fundus_image/'\r\n",
    "    elif mode=='test':\r\n",
    "        path='work/常规赛：PALM眼底彩照视盘探测与分割/PALM-Testing400-Images/'\r\n",
    "    else:\r\n",
    "        raise Exception(\"mode can only be one of ['train', 'test']\")\r\n",
    "    \r\n",
    "    # 获得数据集长度\r\n",
    "    data_length = len(mylist)\r\n",
    "    \r\n",
    "    # 定义数据集每个数据的序号，根据序号读取数据\r\n",
    "    index_list = list(range(data_length))\r\n",
    "    \r\n",
    "    # 定义数据生成器\r\n",
    "    def data_generator():\r\n",
    "        if mode == 'train':\r\n",
    "            # 训练模式下打乱数据\r\n",
    "            random.shuffle(index_list)\r\n",
    "        imgs_list = []\r\n",
    "        labels_list = []\r\n",
    "        for i in index_list:\r\n",
    "            # 将数据处理成希望的类型，即处理成image_size*image_size的向量\r\n",
    "            im = Image.open(path + mylist[i] + '.jpg')\r\n",
    "            im = im.resize((image_size, image_size), Image.ANTIALIAS)\r\n",
    "            if input_channel==1:\r\n",
    "                im = im.convert('L')\r\n",
    "                img = np.array(im).reshape(1, -1).astype(np.float32)/255\r\n",
    "            imgs_list.append(img.tolist()[0]) \r\n",
    "\r\n",
    "            # 读取标签\r\n",
    "            if mode == 'train':\r\n",
    "                im = Image.open('work/常规赛：PALM眼底彩照视盘探测与分割/Train/Disc_Masks/' + mylist[i] + '.bmp')\r\n",
    "                im = im.resize((image_size, image_size), Image.ANTIALIAS)\r\n",
    "                label = np.array(im).astype(np.int64)/255\r\n",
    "                label = label.astype(np.int64)\r\n",
    "                label = label.reshape(1, -1)\r\n",
    "                label = label.tolist()[0]\r\n",
    "            else: label=[]\r\n",
    "            labels_list.append(label)\r\n",
    "            if len(imgs_list) == batchsize:\r\n",
    "                # 获得一个batchsize的数据，并返回\r\n",
    "                yield np.array(imgs_list), np.array(labels_list)\r\n",
    "                # 清空数据读取列表\r\n",
    "                imgs_list = []\r\n",
    "                labels_list = []\r\n",
    "    \r\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\r\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\r\n",
    "        if len(imgs_list) > 0:\r\n",
    "            yield np.array(imgs_list), np.array(labels_list)\r\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 获得数据列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name = [name for name in os.listdir('work/常规赛：PALM眼底彩照视盘探测与分割/Train/fundus_image') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "train_name_list=[]\r\n",
    "for i in name:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    train_name_list.append(tmp[0])\r\n",
    "\r\n",
    "name = [name for name in os.listdir('work/常规赛：PALM眼底彩照视盘探测与分割/PALM-Testing400-Images') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "test_name_list=[]\r\n",
    "for i in name:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    test_name_list.append(tmp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 构建模型\r\n",
    "model=Mymodel()\r\n",
    "\r\n",
    "model.train()\r\n",
    "\r\n",
    "# 构建用于分批读取数据训练的数据读取器\r\n",
    "train_loader = load_data(train_name_list,mode='train')\r\n",
    "\r\n",
    "opt = paddle.optimizer.Adam(learning_rate=0.001, weight_decay=paddle.regularizer.L2Decay(coeff=1e-5),parameters=model.parameters())\r\n",
    "\r\n",
    "print('train start')\r\n",
    "\r\n",
    "# 正式训练\r\n",
    "for epoch_id in range(epoch_num):\r\n",
    "    for batch_id, data in enumerate(train_loader()):\r\n",
    "        images, labels = data\r\n",
    "        images = paddle.to_tensor(images)\r\n",
    "        labels = paddle.to_tensor(labels) \r\n",
    "        images = images.astype(dtype='float32')\r\n",
    "        labels = labels.astype(dtype='float32')\r\n",
    "        \r\n",
    "        predicts = model(images)\r\n",
    "        loss = F.square_error_cost(predicts, labels)\r\n",
    "        avg_loss = paddle.mean(loss)\r\n",
    "\r\n",
    "        if 1:\r\n",
    "            print(\"{} epoch {} batch: los is {}\".format(epoch_id,batch_id,avg_loss.numpy()))\r\n",
    "        \r\n",
    "        #后向传播，更新参数的过程\r\n",
    "        avg_loss.backward()\r\n",
    "        opt.step()\r\n",
    "        opt.clear_grad()\r\n",
    "\r\n",
    "print('train finish')\r\n",
    "\r\n",
    "paddle.save(model.state_dict(), 'Mymodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Mymodel()\r\n",
    "param_dict = paddle.load('./Mymodel')\r\n",
    "model.load_dict(param_dict)\r\n",
    "\r\n",
    "test_loader = load_data(test_name_list,mode='test')\r\n",
    "\r\n",
    "print('test start')\r\n",
    "\r\n",
    "# 进行预测，将结果保存在mylist里\r\n",
    "mylist=[]\r\n",
    "for batch_id, data in enumerate(test_loader()):\r\n",
    "        print(batch_id)\r\n",
    "        images, labels = data\r\n",
    "        images = paddle.to_tensor(images)\r\n",
    "        images = images.astype(dtype='float32')\r\n",
    "        \r\n",
    "        predicts = model(images)\r\n",
    "        mylist=mylist+list(predicts.numpy())\r\n",
    "\r\n",
    "print('test finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 打包结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir './Disc_Segmentation/'\r\n",
    "\r\n",
    "# 定义卷积让结果变得平滑一点\r\n",
    "c_size=5\r\n",
    "w=np.ones([c_size,c_size]).astype(dtype='float32')/(c_size*c_size)\r\n",
    "w = w.reshape([1, 1, c_size, c_size])\r\n",
    "conv = Conv2D(in_channels=1, out_channels=1, kernel_size=[c_size, c_size],weight_attr=paddle.ParamAttr(initializer=Assign(value=w)),padding=int((c_size-1)/2),padding_mode='reflect')\r\n",
    "\r\n",
    "for i in range(len(test_name_list)):\r\n",
    "    if i%50==0:\r\n",
    "        print(i,end=\" \")\r\n",
    "        print(len(test_name_list))\r\n",
    "    # 读取原图片的尺寸，用于缩放预测结果到原尺寸\r\n",
    "    picdir='work/常规赛：PALM眼底彩照视盘探测与分割/PALM-Testing400-Images/' + test_name_list[i] + '.jpg'\r\n",
    "    im = Image.open(picdir)\r\n",
    "    width=np.array(im).shape[1]\r\n",
    "    height=np.array(im).shape[0]\r\n",
    "    \r\n",
    "    picdir='./Disc_Segmentation/' + test_name_list[i] + '.png'\r\n",
    "    tmp=mylist[i].reshape(image_size,image_size).astype('int')\r\n",
    "    \r\n",
    "    # 平滑处理\r\n",
    "    x = paddle.to_tensor(tmp,dtype='float32')\r\n",
    "    x = paddle.reshape(x,[1, 1, image_size, image_size])\r\n",
    "    y = conv(x)\r\n",
    "    tmp = y.numpy().reshape(image_size,image_size).round()*255\r\n",
    "\r\n",
    "    img = Image.fromarray(tmp.astype('uint8'))\r\n",
    "    im = img.resize((width, height), Image.ANTIALIAS)\r\n",
    "    im.save(picdir)\r\n",
    "\r\n",
    "# 打包结果\r\n",
    "! zip -q -r result.zip ./Disc_Segmentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结和一些讨论\n",
    "\n",
    "1. 根据结果可以看到，这种全连接的架构还是能够学习到一些信息的，主要是圆形瞳孔的信息，但并不代表学习到的内容是所需要的划分目标，有时候也会将其他的圆形赋值黑色像素。<br />\n",
    "2. 本程序之所以能够分数不错，主要是测试集大多都是需要划分的，很少有阴性数据。<br />\n",
    "3. 最后的平滑处理虽然能够对得分有一些改善，但是改善是非常有限的，所以还是应该从基础架构入手。<br />\n",
    "4. 由于上个月我被NLP吸引过去了，所以这个问题没有进行非常深入的了解，虽然这个模型较为简朴，但是也还可以进行一些优化，比如在网络内增加卷积层，也许会有一些效果的提升。<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
